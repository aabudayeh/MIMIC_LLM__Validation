{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d1c00c-b6c2-4b30-9c0f-22b7e341f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simple_icd_10_cm as cm\n",
    "import os, json, time\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68237212-eed0-4737-93d9-3b9e949698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, filter, and sample (n=10,000) the data\n",
    "def load_sampled_mimic(path=\"processed_data/mimiciv_icd10.parquet\", n=10_000, min_codes=5, max_codes=11):\n",
    "    df = pd.read_parquet(path, columns=[\"text\", \"diagnosis_codes\", \"note_id\"])\n",
    "    df = df[df[\"diagnosis_codes\"].apply(lambda x: isinstance(x, (list, np.ndarray)) and min_codes <= len(x) < max_codes)]\n",
    "    return df.sample(n=min(n, len(df)), random_state=42)\n",
    "\n",
    "# Get the title of an ICD code\n",
    "def get_icd_title(code, path=\"processed_data/icd10cm_dict.parquet\"):\n",
    "    df = pd.read_parquet(path)\n",
    "    row = df.loc[df['icd_code'] == code]\n",
    "    return row.iloc[0]['long_title'] if not row.empty else \"Unknown\"\n",
    "\n",
    "# Create structured input format\n",
    "def format_row(row, title_dict_path=\"processed_data/icd10cm_dict.parquet\"):\n",
    "    summary = row['text']\n",
    "    gold = row['diagnosis_codes']\n",
    "\n",
    "    out = []\n",
    "    for code in gold:\n",
    "        cat = code.split('.')[0]\n",
    "        diffs = [d for d in cm.get_descendants(cat) if d != code and d not in gold]\n",
    "        title = cm.get_description(code) if cm.is_valid_item(code) else get_icd_title(code, title_dict_path)\n",
    "        diff_list = [{\"code\": d, \"title\": cm.get_description(d) if cm.is_valid_item(d) else get_icd_title(d, title_dict_path)} for d in diffs]\n",
    "        out.append({\"code\": code, \"title\": title, \"differential_codes\": diff_list})\n",
    "\n",
    "    return {\"discharge_summary\": summary, \"icd_gold_standard\": out}\n",
    "\n",
    "# Loads the input file or the df and then processes and saves the input file\n",
    "def process_and_save(path=\"processed_data/processed_inputs_with_ids.jsonl\",\n",
    "                     mimic_path=\"processed_data/mimiciv_icd10.parquet\", n=10_000, min_codes=5, max_codes=11):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Loading saved data from {path}\")\n",
    "        with open(path) as f:\n",
    "            return [json.loads(line) for line in f]\n",
    "    df = load_sampled_mimic(mimic_path, n, min_codes, max_codes)\n",
    "    inputs = [format_row(row) for _, row in tqdm(df.iterrows(), total=len(df))]\n",
    "    with open(path, \"w\") as f:\n",
    "        f.writelines(json.dumps(item) + \"\\n\" for item in inputs)\n",
    "    print(f\"Saved {len(inputs)} entries to {path}\")\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e07a17f0-2ff2-41c5-8a92-a06e48e0181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved data from processed_data/processed_inputs_with_ids.jsonl\n"
     ]
    }
   ],
   "source": [
    "inputs = process_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "166057be-9ba2-454e-9869-7a1b972eb10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"discharge_summary\": \"str\",\n",
      "    \"icd_gold_standard\": [\n",
      "      {\n",
      "        \"code\": \"str\",\n",
      "        \"title\": \"str\",\n",
      "        \"differential_codes\": [\n",
      "          {\n",
      "            \"code\": \"str\",\n",
      "            \"title\": \"str\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"note_id\": \"str\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def json_structure(data, indent=0):\n",
    "    prefix = \"  \" * indent\n",
    "    if isinstance(data, dict):\n",
    "        result = {}\n",
    "        for k, v in data.items():\n",
    "            result[k] = json_structure(v, indent+1)\n",
    "        return result\n",
    "    elif isinstance(data, list):\n",
    "        if data:\n",
    "            return [json_structure(data[0], indent+1)]\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        return type(data).__name__\n",
    "\n",
    "# Example\n",
    "data = inputs\n",
    "\n",
    "print(json.dumps(json_structure(data), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42555a8a-745e-4ad8-b427-9ee75ae1d38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z72.0', 'E86.1', 'L03.012', 'N17.9', 'Z21']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "n = 0   # <-- Change this to the index you want to compare\n",
    "\n",
    "# Load JSON output\n",
    "with open(\"processed_data/icd_verification_ckpt.json\", \"r\") as f:\n",
    "    outputs = json.load(f)\n",
    "\n",
    "# Load JSONL input\n",
    "inputs = []\n",
    "with open(\"processed_data/processed_inputs.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        inputs.append(json.loads(line))\n",
    "\n",
    "# Extract only the ICD codes from input (excluding differential_codes)\n",
    "input_icd = inputs[n].get(\"icd_gold_standard\", [])\n",
    "\n",
    "# Extract just the codes from the input\n",
    "input_codes = [entry['code'] for entry in input_icd]\n",
    "\n",
    "# If outputs is a dict, use str(n) as the key\n",
    "if isinstance(outputs, dict):\n",
    "    output_icd = outputs.get(str(n), None)\n",
    "elif isinstance(outputs, list):\n",
    "    output_icd = outputs[n] if n < len(outputs) else None\n",
    "else:\n",
    "    output_icd = None\n",
    "\n",
    "input_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50cdcdfc-67f2-4b29-be8f-4912d84dd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " output_icd = outputs['2437']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f063b660-9ca7-4131-be0b-aa85c8e9ee78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 'r64',\n",
       "  'title': 'cachexia',\n",
       "  'evidence': ['general - cachectic, in no distress'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': \"the discharge summary directly describes the patient as 'cachectic,' supporting the use of code r64.\"}},\n",
       " {'code': 'r00.1',\n",
       "  'title': 'bradycardia, unspecified',\n",
       "  'evidence': ['patient states that she has had difficulty with eating for about a year.',\n",
       "   'cardiovasc - regular, borderlien bradycardic, normal s1/s2, no murmur',\n",
       "   '# anorexia nervosa presented voluntarily with symptoms of severe malnutrition/underweight with bradycardia.'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': \"the discharge summary mentions bradycardia multiple times in the context of the patient's anorexia nervosa and malnutrition, supporting the use of r00.1.\"}},\n",
       " {'code': 'n39.0',\n",
       "  'title': 'urinary tract infection, site not specified',\n",
       "  'evidence': 'no evidence',\n",
       "  'accuracy': {'is_accurate': None,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'not applicable (no evidence).'}},\n",
       " {'code': 'd53.9',\n",
       "  'title': 'nutritional anemia, unspecified',\n",
       "  'evidence': ['# normocytic anemia hemoglobin downtrended throughout admission (admission hg 12.7 --> 9.3). no evidence of hemodynamic stability or active bleeding. found to have elevated ferritin, likely in setting of malnutrition/illness, other anemia studies unremarkable.'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'the discharge summary describes normocytic anemia likely due to malnutrition, supporting the use of d53.9.'}},\n",
       " {'code': 'n91.1',\n",
       "  'title': 'secondary amenorrhea',\n",
       "  'evidence': ['patient states that she has had irregular periods for over 3 months.',\n",
       "   '# amenorrhea secondary to anorexia, continued home ocp.'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'the discharge summary clearly states secondary amenorrhea due to anorexia, supporting the use of n91.1.'}},\n",
       " {'code': 'z68.1',\n",
       "  'title': 'body mass index [bmi] 19.9 or less, adult',\n",
       "  'evidence': ['bmi on arrival was 13.'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'the discharge summary notes a bmi of 13, which falls under z68.1 (bmi 19.9 or less).'}},\n",
       " {'code': 'r74.0',\n",
       "  'title': 'nonspecific elevation of levels of transaminase and lactic acid dehydrogenase [ldh]',\n",
       "  'evidence': ['labs were notable for: amylase 106, alt 105/ast 55',\n",
       "   '# elevated tranaminases noted to have mild transaminase elevation in the setting of poor nutritional intake.'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'the discharge summary describes elevated transaminases due to malnutrition, supporting the use of r74.0.'}},\n",
       " {'code': 'f50.01',\n",
       "  'title': 'anorexia nervosa, restricting type',\n",
       "  'evidence': ['patient states that she has had difficulty with eating for about a year.',\n",
       "   'she notes that since ___, she had been on a diet in attempt to lose weight. she ate roughly ___ meals per day (large amounts of salad) and would work out for 2 hours per day.',\n",
       "   '# anorexia nervosa presented voluntarily with symptoms of severe malnutrition/underweight with bradycardia.'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'the discharge summary clearly describes anorexia nervosa, restricting type, with no evidence of binge eating/purging, supporting the use of f50.01.'}},\n",
       " {'code': 'i47.1',\n",
       "  'title': 'supraventricular tachycardia',\n",
       "  'evidence': 'no evidence',\n",
       "  'accuracy': {'is_accurate': None,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'not applicable (no evidence).'}},\n",
       " {'code': 'e43',\n",
       "  'title': 'unspecified severe protein-calorie malnutrition',\n",
       "  'evidence': ['# anorexia nervosa presented voluntarily with symptoms of severe malnutrition/underweight with bradycardia.',\n",
       "   'general - cachectic, in no distress'],\n",
       "  'accuracy': {'is_accurate': True,\n",
       "   'better_alternative': None,\n",
       "   'justification': 'the discharge summary describes severe malnutrition associated with anorexia nervosa, supporting the use of e43.'}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e22e915f-5f76-45e7-821e-e63f4485247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "\n",
    "def add_note_ids(jsonl=\"processed_data/processed_inputs.jsonl\",\n",
    "                 parquet=\"processed_data/mimiciv_icd10.parquet\",\n",
    "                 out=\"processed_data/processed_inputs_with_ids.jsonl\",\n",
    "                 n=10_000, min_codes=5, max_codes=11):\n",
    "\n",
    "    df = load_sampled_mimic(path=parquet, n=n, min_codes=min_codes, max_codes=max_codes)\n",
    "\n",
    "    data = [json.loads(l) for l in open(jsonl)]\n",
    "    print(len(data))\n",
    "    print(len(df))\n",
    "    assert len(data)==len(df)\n",
    "\n",
    "    for d,(_,r) in zip(data,df.iterrows()):\n",
    "        if len(d[\"discharge_summary\"])!=len(r.text):\n",
    "            raise ValueError(\"Length mismatch\")\n",
    "        d[\"note_id\"]=r.note_id\n",
    "\n",
    "    with open(out,\"w\") as f: f.writelines(json.dumps(d)+\"\\n\" for d in data)\n",
    "    print(f\"Saved {len(data)} with note_id → {out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9e7f93-8dfd-41bc-9b70-4c4863032428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "Saved 10000 with note_id → processed_data/processed_inputs_with_ids.jsonl\n"
     ]
    }
   ],
   "source": [
    "add_note_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662aee60-2090-4322-b8fd-c54749378da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def validate_icd_codes(jsonl=\"processed_data/processed_inputs_with_ids.jsonl\",\n",
    "                       parquet=\"processed_data/mimiciv_icd10.parquet\"):\n",
    "    # Load dataframe with note_id and diagnosis_codes\n",
    "    df = pd.read_parquet(parquet, columns=[\"note_id\",\"diagnosis_codes\"])\n",
    "    df_dict = df.set_index(\"note_id\")[\"diagnosis_codes\"].to_dict()\n",
    "\n",
    "    # Load JSONL\n",
    "    data = [json.loads(l) for l in open(jsonl)]\n",
    "\n",
    "    mismatches = []\n",
    "    for item in data:\n",
    "        nid = item.get(\"note_id\")\n",
    "        if nid not in df_dict:\n",
    "            mismatches.append((nid, \"note_id not in DF\"))\n",
    "            continue\n",
    "        json_codes = sorted([x[\"code\"] for x in item[\"icd_gold_standard\"]])\n",
    "        df_codes = sorted(df_dict[nid])\n",
    "        if json_codes != df_codes:\n",
    "            mismatches.append((nid, {\"json\": json_codes, \"df\": df_codes}))\n",
    "\n",
    "    if not mismatches:\n",
    "        print(\"✅ All ICD codes match the original dataframe.\")\n",
    "    else:\n",
    "        print(f\"❌ {len(mismatches)} mismatches found:\")\n",
    "        for m in mismatches[:10]:  # show first 10 for brevity\n",
    "            print(m)\n",
    "\n",
    "    return mismatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a05de-5b4a-4fab-83be-8cad79c5eff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f264e1e-856c-45de-920a-ccaa60fe8a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'combined': PosixPath('processed_data/combined.json'),\n",
       " 'train': PosixPath('processed_data/train.json'),\n",
       " 'val': PosixPath('processed_data/val.json'),\n",
       " 'test': PosixPath('processed_data/test.json')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, random, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def _load_json_or_jsonl(p: str) -> List[Dict[str,Any]]:\n",
    "    s = Path(p).read_text().strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    if s[0] == '[':\n",
    "        return json.loads(s)\n",
    "    return [json.loads(l) for l in s.splitlines() if l.strip()]\n",
    "\n",
    "def _load_json(p: str) -> Dict[str,Any]:\n",
    "    return json.loads(Path(p).read_text())\n",
    "\n",
    "def _has_evidence(e) -> bool:\n",
    "    if e is None: return False\n",
    "    if isinstance(e, list):\n",
    "        return any(str(x).strip() and str(x).strip().lower() != 'no evidence' for x in e)\n",
    "    s = str(e).strip()\n",
    "    return bool(s) and s.lower() != 'no evidence'\n",
    "\n",
    "def _build_combined(inputs: List[Dict], ckpt: Dict[str,Any]) -> List[Dict]:\n",
    "    out = []\n",
    "    for k, entries in ckpt.items():\n",
    "        try:\n",
    "            i = int(k)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if not (0 <= i < len(inputs)):\n",
    "            continue\n",
    "        note = inputs[i]\n",
    "        mimic_codes = [{'code': c.get('code'), 'title': c.get('title')} \n",
    "                       for c in note.get('icd_gold_standard', [])]\n",
    "        llm_validated = []\n",
    "        llm_accurate = []\n",
    "        for ent in entries:\n",
    "            if not _has_evidence(ent.get('evidence')):\n",
    "                continue\n",
    "            code = ent.get('code')\n",
    "            title = ent.get('title')\n",
    "            accuracy = ent.get('accuracy') or {}\n",
    "            better = accuracy.get('better_alternative') if isinstance(accuracy, dict) else None\n",
    "            llm_validated.append({\n",
    "                'code': code, 'title': title,\n",
    "                'evidence': ent.get('evidence'),\n",
    "                'accuracy': accuracy\n",
    "            })\n",
    "            code2 = better if (isinstance(better, str) and better.strip()) else code\n",
    "            llm_accurate.append({\n",
    "                'code': code2, 'title': title,\n",
    "                'evidence': ent.get('evidence'),\n",
    "                'replaced_from': code if code2 != code else None\n",
    "            })\n",
    "        out.append({\n",
    "            'index': i,\n",
    "            'note_id': note.get('note_id'),\n",
    "            'discharge_summary': note.get('discharge_summary'),\n",
    "            'mimic_codes': mimic_codes,\n",
    "            'llm_validated_codes': llm_validated,\n",
    "            'llm_accurate_codes': llm_accurate\n",
    "        })\n",
    "    return sorted(out, key=lambda x: x['index'])\n",
    "\n",
    "def _split_and_write(all_notes: List[Dict], out_dir: str,\n",
    "                     splits=(0.729, 0.109, 0.162), seed=42) -> Dict[str, Path]:\n",
    "    total = len(all_notes)\n",
    "    rng = random.Random(seed)\n",
    "    idxs = list(range(total))\n",
    "    rng.shuffle(idxs)\n",
    "    n_train = int(round(total * splits[0]))\n",
    "    n_val = int(round(total * splits[1]))\n",
    "    n_train = min(n_train, total)\n",
    "    n_val = min(n_val, total - n_train)\n",
    "    n_test = total - n_train - n_val\n",
    "    train = [all_notes[i] for i in idxs[:n_train]]\n",
    "    val = [all_notes[i] for i in idxs[n_train:n_train + n_val]]\n",
    "    test = [all_notes[i] for i in idxs[n_train + n_val:]]\n",
    "    outp = Path(out_dir)\n",
    "    outp.mkdir(parents=True, exist_ok=True)\n",
    "    (outp / 'combined.json').write_text(json.dumps(all_notes, indent=2))\n",
    "    (outp / 'train.json').write_text(json.dumps(train, indent=2))\n",
    "    (outp / 'val.json').write_text(json.dumps(val, indent=2))\n",
    "    (outp / 'test.json').write_text(json.dumps(test, indent=2))\n",
    "    return {'combined': outp/'combined.json', 'train': outp/'train.json',\n",
    "            'val': outp/'val.json', 'test': outp/'test.json'}\n",
    "\n",
    "def process_icd_validation(inputs_path: str,\n",
    "                           ckpt_path: str,\n",
    "                           out_dir: str = 'processed_data',\n",
    "                           splits=(0.729, 0.109, 0.162),\n",
    "                           seed: int = 42) -> Dict[str, Path]:\n",
    "    inputs = _load_json_or_jsonl(inputs_path)\n",
    "    ckpt = _load_json(ckpt_path)\n",
    "    combined = _build_combined(inputs, ckpt)\n",
    "    return _split_and_write(combined, out_dir, splits, seed)\n",
    "\n",
    "# one-line run (will execute when you run the file / paste into REPL):\n",
    "process_icd_validation('processed_data/processed_inputs_with_ids.jsonl',\n",
    "                       'processed_data/icd_verification_ckpt.json',\n",
    "                       out_dir='processed_data', splits=(0.729,0.109,0.162), seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b43e8b-b9db-4bff-9678-795bfe37cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def normalize_code(c):\n",
    "    return c.strip().upper()\n",
    "\n",
    "codes = {normalize_code(c) for c in codes}\n",
    "\n",
    "\n",
    "def describe_groups(data):\n",
    "    defs = {\n",
    "        \"mimic_codes\": \"MIMIC gold standard (original ICD codes in dataset)\",\n",
    "        \"llm_validated_codes\": \"LLM validated codes (only those with evidence kept)\",\n",
    "        \"llm_accurate_codes\": \"LLM accurate codes (validated + better alternatives replacing originals)\"\n",
    "    }\n",
    "    print(\"\\n=== Group Definitions ===\")\n",
    "    for k,v in defs.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    stats, all_sets = {}, {}\n",
    "    for grp in defs:\n",
    "        codes_per_note = [len(note.get(grp, [])) for note in data]\n",
    "        all_codes = [c['code'] for note in data for c in note.get(grp,[])]\n",
    "        all_sets[grp] = set(all_codes)\n",
    "        stats[grp] = {\n",
    "            \"Notes\": len(data),\n",
    "            \"Total codes\": len(all_codes),\n",
    "            \"Avg codes/note\": round(sum(codes_per_note)/len(data),2),\n",
    "            \"Median codes/note\": sorted(codes_per_note)[len(data)//2],\n",
    "            \"Unique codes\": len(set(all_codes)),\n",
    "            \"Top5\": Counter(all_codes).most_common(5)\n",
    "        }\n",
    "\n",
    "    print(\"\\n=== Descriptive Stats ===\")\n",
    "    for grp,vals in stats.items():\n",
    "        print(f\"\\n{grp}:\")\n",
    "        for k,v in vals.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "\n",
    "    print(\"\\n=== Overlap Between Groups (unique codes) ===\")\n",
    "    keys = list(defs.keys())\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i+1,len(keys)):\n",
    "            a,b = keys[i],keys[j]\n",
    "            inter = len(all_sets[a] & all_sets[b])\n",
    "            print(f\"{a} ∩ {b}: {inter}\")\n",
    "\n",
    "    # evidence / accuracy checks\n",
    "    no_evidence, with_evidence_not_acc = 0,0\n",
    "    for note in data:\n",
    "        for ent in note.get(\"llm_validated_codes\",[]):\n",
    "            ev = ent.get(\"evidence\")\n",
    "            acc = ent.get(\"accuracy\",{})\n",
    "            if not ev or (isinstance(ev,str) and ev.strip().lower()==\"no evidence\") or (isinstance(ev,list) and not any(x.strip() for x in ev)):\n",
    "                no_evidence+=1\n",
    "            elif acc and acc.get(\"is_accurate\") is False:\n",
    "                with_evidence_not_acc+=1\n",
    "\n",
    "    print(\"\\n=== Evidence / Accuracy Checks ===\")\n",
    "    print(f\"Codes lacking evidence (but present in checkpoint): {no_evidence}\")\n",
    "    print(f\"Codes with evidence but flagged not accurate: {with_evidence_not_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2c6c98-685a-49ff-8bb9-8c984b7ca4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Group Definitions ===\n",
      "mimic_codes: MIMIC gold standard (original ICD codes in dataset)\n",
      "llm_validated_codes: LLM validated codes (only those with evidence kept)\n",
      "llm_accurate_codes: LLM accurate codes (validated + better alternatives replacing originals)\n",
      "\n",
      "=== Descriptive Stats ===\n",
      "\n",
      "mimic_codes:\n",
      "  Notes: 9528\n",
      "  Total codes: 73389\n",
      "  Avg codes/note: 7.7\n",
      "  Median codes/note: 8\n",
      "  Unique codes: 4453\n",
      "  Top5: [('I10', 3574), ('E78.5', 2326), ('Z87.891', 1938), ('K21.9', 1651), ('F32.9', 1318)]\n",
      "\n",
      "llm_validated_codes:\n",
      "  Notes: 9528\n",
      "  Total codes: 55638\n",
      "  Avg codes/note: 5.84\n",
      "  Median codes/note: 6\n",
      "  Unique codes: 4081\n",
      "  Top5: [('i10', 3137), ('e78.5', 1982), ('k21.9', 1142), ('f32.9', 953), ('f41.9', 882)]\n",
      "\n",
      "llm_accurate_codes:\n",
      "  Notes: 9528\n",
      "  Total codes: 55638\n",
      "  Avg codes/note: 5.84\n",
      "  Median codes/note: 6\n",
      "  Unique codes: 4691\n",
      "  Top5: [('i10', 3140), ('e78.5', 1922), ('k21.9', 1126), ('f32.9', 871), ('e11.9', 793)]\n",
      "\n",
      "=== Overlap Between Groups (unique codes) ===\n",
      "mimic_codes ∩ llm_validated_codes: 6\n",
      "mimic_codes ∩ llm_accurate_codes: 6\n",
      "llm_validated_codes ∩ llm_accurate_codes: 3828\n",
      "\n",
      "=== Evidence / Accuracy Checks ===\n",
      "Codes lacking evidence (but present in checkpoint): 0\n",
      "Codes with evidence but flagged not accurate: 6097\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open(\"processed_data/combined.json\"))\n",
    "describe_groups(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52eb2008-c3ff-424d-aca6-6b299be7b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "def load_json_or_jsonl(p: str):\n",
    "    s = Path(p).read_text().strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    if s[0] == '[':\n",
    "        return json.loads(s)\n",
    "    return [json.loads(l) for l in s.splitlines() if l.strip()]\n",
    "\n",
    "def load_json(p: str):\n",
    "    return json.loads(Path(p).read_text())\n",
    "\n",
    "def validate_index(idx: int,\n",
    "                   inputs_path='processed_data/processed_inputs_with_ids.jsonl',\n",
    "                   ckpt_path='processed_data/icd_verification_ckpt.json',\n",
    "                   combined_path='processed_data/combined.json') -> None:\n",
    "    inputs = load_json_or_jsonl(inputs_path)\n",
    "    ckpt = load_json(ckpt_path)\n",
    "    combined = load_json(combined_path)\n",
    "\n",
    "    note = inputs[idx]\n",
    "    mimic = [{'code': c['code'], 'title': c['title']}\n",
    "             for c in note.get('icd_gold_standard', [])]\n",
    "\n",
    "    ckpt_entry = ckpt.get(str(idx), [])\n",
    "    comb_entry = next((c for c in combined if c['index'] == idx), None)\n",
    "\n",
    "    print(f\"\\n=== Index {idx} / Note ID {note.get('note_id')} ===\")\n",
    "    print(\"\\n--- MIMIC gold-standard ---\")\n",
    "    for c in mimic:\n",
    "        print(f\"  {c['code']} | {c['title']}\")\n",
    "\n",
    "    print(\"\\n--- Checkpoint (LLM raw) ---\")\n",
    "    for e in ckpt_entry:\n",
    "        code, title = e.get('code'), e.get('title')\n",
    "        ev = e.get('evidence')\n",
    "        acc = e.get('accuracy')\n",
    "        print(f\"  {code} | {title}\\n    evidence: {ev}\\n    accuracy: {acc}\")\n",
    "\n",
    "    if comb_entry:\n",
    "        print(\"\\n--- LLM validated codes ---\")\n",
    "        for c in comb_entry['llm_validated_codes']:\n",
    "            print(f\"  {c['code']} | {c['title']}\")\n",
    "\n",
    "        print(\"\\n--- LLM accurate codes ---\")\n",
    "        for c in comb_entry['llm_accurate_codes']:\n",
    "            rep = f\" (replaced from {c['replaced_from']})\" if c.get('replaced_from') else \"\"\n",
    "            print(f\"  {c['code']} | {c['title']}{rep}\")\n",
    "    else:\n",
    "        print(\"\\n(No combined entry for this index)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbe6ab-31b1-4028-872b-75822f4b1c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
